{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dde45e0-ce3d-4245-9f6b-d8fcbe49198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import tensorflow  as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,UpSampling2D,InputLayer,Reshape\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.layers import Dropout,Activation,BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee1b247-5f16-475f-843b-d9a31ccadc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定圖片大小和路徑\n",
    "img_width, img_height = 224, 224  # ResNet50的標準輸入大小\n",
    "train_data_dir = \"C:/Users/user/Desktop/MLwork2/train\"\n",
    "test_data_dir = \"C:/Users/user/Desktop/MLwork2/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70eafecf-4b80-41a7-866c-3da0945d6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = [20, 40, 60]\n",
    "batch_size_list = [8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32abe247-a115-4002-b821-bbab84ae4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定結果儲存目錄\n",
    "results_dir = 'C:/Users/user/Desktop/MLWORK/ResNet50'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d76297d-d8ab-4f40-bad0-eeb053692b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建CSV檔案記錄結果\n",
    "def create_result_csv_files():\n",
    "    csv_files = {}\n",
    "    \n",
    "    # 創建基本模型結果CSV\n",
    "    base_csv_path = os.path.join(results_dir, \"ResNet50_base_model_results.csv\")\n",
    "    with open(base_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Model', 'Epochs', 'Train Accuracy', 'Train Loss', 'Val Accuracy', 'Val Loss', 'Test Accuracy', 'Test Loss'])\n",
    "    csv_files['base'] = base_csv_path\n",
    "    \n",
    "    # 創建微調模型結果CSV\n",
    "    tuned_csv_path = os.path.join(results_dir, \"ResNet50_fine_tuned_model_results.csv\")\n",
    "    with open(tuned_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Model', 'Epochs', 'Train Accuracy', 'Train Loss', 'Val Accuracy', 'Val Loss', 'Test Accuracy', 'Test Loss'])\n",
    "    csv_files['tuned'] = tuned_csv_path\n",
    "    \n",
    "    # 創建模型比較CSV\n",
    "    comparison_csv_path = os.path.join(results_dir, \"ResNet50_tuned_or_not_comparison.csv\")\n",
    "    with open(comparison_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Model', 'Epochs', 'Base Accuracy', 'Base Loss', 'Tuned Accuracy', 'Tuned Loss', 'Improvement'])\n",
    "    csv_files['comparison'] = comparison_csv_path\n",
    "    \n",
    "    return csv_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fa8356-58b2-417c-81bd-f52dbc5f3b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料生成器 (無資料增強)\n",
    "def create_data_generators(batch_size):\n",
    "    # 僅做標準化處理，不增強數據\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        validation_split=0.2  # 保留驗證分割\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198cf5c9-3ee0-4818-b22e-a849b2156475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建ResNet50模型\n",
    "def create_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "    \n",
    "    # 凍結基礎模型的層\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # 添加新的分類層\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # ResNet50通常使用GlobalAveragePooling而非Flatten\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')  # 二元分類\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b67457e-0938-4d1d-9d8d-d536d5b6b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微調模型：解凍部分基礎模型的層\n",
    "def fine_tune_model(model):\n",
    "    # 計算要解凍的層數（所有模型使用相同的比例：頂部20%的層）\n",
    "    # 確保 model 是一個 Sequential 模型且第一個層是 base_model\n",
    "    if isinstance(model, Sequential) and len(model.layers) > 0:\n",
    "        base_model = model.layers[0] # <-- 正確地獲取 ResNet50 基礎模型\n",
    "    else:\n",
    "        print(\"Warning: model structure unexpected, could not identify base_model for fine-tuning.\")\n",
    "        return model\n",
    "\n",
    "    if not hasattr(base_model, 'layers'):\n",
    "        print(\"Warning: base_model does not have layers to unfreeze.\")\n",
    "        return model\n",
    "\n",
    "    total_layers = len(base_model.layers) # <-- 計算 ResNet50 基礎模型的層數\n",
    "    if total_layers == 0:\n",
    "         print(\"Warning: base_model has no layers to unfreeze.\")\n",
    "         return model\n",
    "\n",
    "    unfreeze_layers = max(0, int(total_layers * 0.2))  # 解凍頂部20%的層\n",
    "\n",
    "    # 先凍結所有基礎模型的層\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 然後解凍 ResNet50 基礎模型頂部的指定層數\n",
    "    for layer in base_model.layers[-unfreeze_layers:]: # <-- 解凍 ResNet50 基礎模型的頂部層\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Fine-tuning model: Unfrozen {unfreeze_layers} layers out of {total_layers} total layers in the base model.\")\n",
    "\n",
    "    # 重新編譯模型以應用更低的學習率\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),  # 更低的學習率用於微調\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5827a7bc-c1b0-4d95-b952-ae498eb2d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練和評估模型\n",
    "def train_and_evaluate_model(model, train_generator, val_generator, test_generator, \n",
    "                           model_name, epochs, batch_size, is_fine_tuned=False):\n",
    "    model_prefix = \"fine_tuned_\" if is_fine_tuned else \"base_\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(results_dir, f\"{model_prefix}{model_name}_e{epochs}.h5\"),\n",
    "            save_best_only=True,\n",
    "            monitor='val_accuracy'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # 訓練模型\n",
    "    print(f\"Training {'fine-tuned' if is_fine_tuned else 'base'} {model_name} with epochs={epochs}, batch_size={batch_size}\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # 評估訓練集\n",
    "    train_eval = model.evaluate(train_generator)\n",
    "    train_loss, train_acc = train_eval\n",
    "    \n",
    "    # 評估驗證集\n",
    "    val_eval = model.evaluate(val_generator)\n",
    "    val_loss, val_acc = val_eval\n",
    "    \n",
    "    # 評估測試集\n",
    "    test_eval = model.evaluate(test_generator)\n",
    "    test_loss, test_acc = test_eval\n",
    "    \n",
    "    # 繪製訓練歷史\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 準確率圖\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], 'b', label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'r', label='Validation Accuracy')\n",
    "    plt.title(f'{model_prefix.capitalize()} {model_name} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 損失函數圖\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], 'b', label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], 'r', label='Validation Loss')\n",
    "    plt.title(f'{model_prefix.capitalize()} {model_name} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f\"{model_prefix.lower()}_{model_name.lower()}_e{epochs}_b{batch_size}_history.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'train_accuracy': train_acc,\n",
    "        'train_loss': train_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_loss': test_loss\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d10ab06-06f1-4a4c-a6c7-218a69db1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將結果保存到CSV\n",
    "def save_results_to_csv(results, csv_path, model_name, epochs, is_fine_tuned=False):\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            model_name,\n",
    "            epochs,\n",
    "            results['train_accuracy'],\n",
    "            results['train_loss'],\n",
    "            results['val_accuracy'],\n",
    "            results['val_loss'],\n",
    "            results['test_accuracy'],\n",
    "            results['test_loss']\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8543e673-e1de-4677-9a68-e309e12f46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存比較結果到CSV\n",
    "def save_comparison_to_csv(base_results, tuned_results, csv_path, model_name, epochs):\n",
    "    improvement = tuned_results['test_accuracy'] - base_results['test_accuracy']\n",
    "    \n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            model_name,\n",
    "            epochs,\n",
    "            base_results['test_accuracy'],\n",
    "            base_results['test_loss'],\n",
    "            tuned_results['test_accuracy'],\n",
    "            tuned_results['test_loss'],\n",
    "            improvement\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1872d9d1-f3f2-4424-a19c-ed4042e91418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Stage 1: Training and Evaluating Base Models ========\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 20, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=20, batch_size=8\n",
      "Epoch 1/20\n",
      "22/22 [==============================] - 22s 627ms/step - loss: 0.8286 - accuracy: 0.5455 - val_loss: 0.7033 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 11s 489ms/step - loss: 0.7942 - accuracy: 0.4489 - val_loss: 0.6947 - val_accuracy: 0.4750\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 0.7773 - accuracy: 0.4489 - val_loss: 0.6917 - val_accuracy: 0.5250\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 11s 514ms/step - loss: 0.7351 - accuracy: 0.5057 - val_loss: 0.6896 - val_accuracy: 0.5750\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.6859 - accuracy: 0.5568 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 11s 493ms/step - loss: 0.7344 - accuracy: 0.4830 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 12s 547ms/step - loss: 0.7354 - accuracy: 0.4886 - val_loss: 0.6915 - val_accuracy: 0.6000\n",
      "22/22 [==============================] - 9s 412ms/step - loss: 0.6924 - accuracy: 0.5341\n",
      "6/6 [==============================] - 3s 496ms/step - loss: 0.6916 - accuracy: 0.5227\n",
      "10/10 [==============================] - 5s 504ms/step - loss: 0.6945 - accuracy: 0.4625\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 20, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=20, batch_size=16\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.7688 - accuracy: 0.5170 - val_loss: 0.6907 - val_accuracy: 0.5312\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 11s 944ms/step - loss: 0.7743 - accuracy: 0.5057 - val_loss: 0.6914 - val_accuracy: 0.5312\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 11s 994ms/step - loss: 0.7203 - accuracy: 0.5511 - val_loss: 0.6979 - val_accuracy: 0.3750\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7318 - accuracy: 0.5568 - val_loss: 0.6983 - val_accuracy: 0.4688\n",
      "11/11 [==============================] - 9s 802ms/step - loss: 0.6959 - accuracy: 0.5000\n",
      "3/3 [==============================] - 3s 970ms/step - loss: 0.6957 - accuracy: 0.5000\n",
      "5/5 [==============================] - 5s 1s/step - loss: 0.6959 - accuracy: 0.5000\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 40, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=40, batch_size=8\n",
      "Epoch 1/40\n",
      "22/22 [==============================] - 18s 667ms/step - loss: 0.8071 - accuracy: 0.4432 - val_loss: 0.6935 - val_accuracy: 0.5500\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - 13s 600ms/step - loss: 0.8560 - accuracy: 0.4773 - val_loss: 0.6928 - val_accuracy: 0.5250\n",
      "Epoch 3/40\n",
      "22/22 [==============================] - 15s 684ms/step - loss: 0.8335 - accuracy: 0.4375 - val_loss: 0.6986 - val_accuracy: 0.5000\n",
      "Epoch 4/40\n",
      "22/22 [==============================] - 12s 536ms/step - loss: 0.7521 - accuracy: 0.5398 - val_loss: 0.6921 - val_accuracy: 0.5250\n",
      "Epoch 5/40\n",
      "22/22 [==============================] - 13s 581ms/step - loss: 0.7760 - accuracy: 0.5114 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "22/22 [==============================] - 12s 536ms/step - loss: 0.7429 - accuracy: 0.5170 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "22/22 [==============================] - 11s 512ms/step - loss: 0.7572 - accuracy: 0.4716 - val_loss: 0.6899 - val_accuracy: 0.5250\n",
      "Epoch 8/40\n",
      "22/22 [==============================] - 11s 502ms/step - loss: 0.7643 - accuracy: 0.5000 - val_loss: 0.6961 - val_accuracy: 0.5250\n",
      "Epoch 9/40\n",
      "22/22 [==============================] - 11s 501ms/step - loss: 0.8013 - accuracy: 0.5000 - val_loss: 0.6957 - val_accuracy: 0.5000\n",
      "Epoch 10/40\n",
      "22/22 [==============================] - 11s 521ms/step - loss: 0.7405 - accuracy: 0.5057 - val_loss: 0.6995 - val_accuracy: 0.4750\n",
      "22/22 [==============================] - 9s 398ms/step - loss: 0.6909 - accuracy: 0.5170\n",
      "6/6 [==============================] - 2s 355ms/step - loss: 0.6928 - accuracy: 0.5000\n",
      "10/10 [==============================] - 5s 458ms/step - loss: 0.6969 - accuracy: 0.4875\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 40, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=40, batch_size=16\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 17s 1s/step - loss: 0.8071 - accuracy: 0.5568 - val_loss: 0.7123 - val_accuracy: 0.4375\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7840 - accuracy: 0.4716 - val_loss: 0.6932 - val_accuracy: 0.4688\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7265 - accuracy: 0.5739 - val_loss: 0.6858 - val_accuracy: 0.5625\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.8053 - accuracy: 0.4602 - val_loss: 0.6903 - val_accuracy: 0.5312\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7383 - accuracy: 0.5341 - val_loss: 0.7041 - val_accuracy: 0.4688\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7367 - accuracy: 0.5284 - val_loss: 0.6930 - val_accuracy: 0.4688\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.6922 - accuracy: 0.5000\n",
      "3/3 [==============================] - 3s 756ms/step - loss: 0.6927 - accuracy: 0.4773\n",
      "5/5 [==============================] - 5s 996ms/step - loss: 0.6899 - accuracy: 0.5500\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 60, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=60, batch_size=8\n",
      "Epoch 1/60\n",
      "22/22 [==============================] - 17s 603ms/step - loss: 0.8034 - accuracy: 0.4602 - val_loss: 0.6897 - val_accuracy: 0.5750\n",
      "Epoch 2/60\n",
      "22/22 [==============================] - 11s 489ms/step - loss: 0.7826 - accuracy: 0.4773 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 3/60\n",
      "22/22 [==============================] - 11s 501ms/step - loss: 0.7594 - accuracy: 0.5170 - val_loss: 0.6878 - val_accuracy: 0.5750\n",
      "Epoch 4/60\n",
      "22/22 [==============================] - 11s 495ms/step - loss: 0.7197 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5250\n",
      "Epoch 5/60\n",
      "22/22 [==============================] - 11s 484ms/step - loss: 0.7731 - accuracy: 0.4943 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 6/60\n",
      "22/22 [==============================] - 11s 498ms/step - loss: 0.7456 - accuracy: 0.4943 - val_loss: 0.6914 - val_accuracy: 0.5250\n",
      "22/22 [==============================] - 9s 385ms/step - loss: 0.6922 - accuracy: 0.5625\n",
      "6/6 [==============================] - 2s 298ms/step - loss: 0.6888 - accuracy: 0.5682\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.6926 - accuracy: 0.5000\n",
      "\n",
      "===== Training Base ResNet50 - Epochs: 60, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Training base ResNet50 with epochs=60, batch_size=16\n",
      "Epoch 1/60\n",
      "11/11 [==============================] - 18s 1s/step - loss: 0.7530 - accuracy: 0.5057 - val_loss: 0.6975 - val_accuracy: 0.4688\n",
      "Epoch 2/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7432 - accuracy: 0.4773 - val_loss: 0.6895 - val_accuracy: 0.5312\n",
      "Epoch 3/60\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.7434 - accuracy: 0.5455 - val_loss: 0.6873 - val_accuracy: 0.5938\n",
      "Epoch 4/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7823 - accuracy: 0.4375 - val_loss: 0.6902 - val_accuracy: 0.5625\n",
      "Epoch 5/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7367 - accuracy: 0.5341 - val_loss: 0.6857 - val_accuracy: 0.5000\n",
      "Epoch 6/60\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7433 - accuracy: 0.5000 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 7/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7467 - accuracy: 0.5398 - val_loss: 0.6927 - val_accuracy: 0.4688\n",
      "Epoch 8/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.7280 - accuracy: 0.4886 - val_loss: 0.6849 - val_accuracy: 0.5625\n",
      "Epoch 9/60\n",
      "11/11 [==============================] - 11s 998ms/step - loss: 0.7033 - accuracy: 0.5170 - val_loss: 0.6848 - val_accuracy: 0.5625\n",
      "Epoch 10/60\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7662 - accuracy: 0.4602 - val_loss: 0.6850 - val_accuracy: 0.5312\n",
      "Epoch 11/60\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.7326 - accuracy: 0.4148 - val_loss: 0.6848 - val_accuracy: 0.6562\n",
      "Epoch 12/60\n",
      "11/11 [==============================] - 11s 976ms/step - loss: 0.7188 - accuracy: 0.5114 - val_loss: 0.6981 - val_accuracy: 0.4375\n",
      "11/11 [==============================] - 9s 774ms/step - loss: 0.6902 - accuracy: 0.5511\n",
      "3/3 [==============================] - 2s 629ms/step - loss: 0.6887 - accuracy: 0.5455\n",
      "5/5 [==============================] - 5s 910ms/step - loss: 0.6904 - accuracy: 0.5375\n",
      "\n",
      "======== Stage 2: Fine-tuning Models ========\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 20, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=20, batch_size=8\n",
      "Epoch 1/20\n",
      "22/22 [==============================] - 17s 592ms/step - loss: 0.7621 - accuracy: 0.4830 - val_loss: 0.7529 - val_accuracy: 0.4750\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 11s 492ms/step - loss: 0.6378 - accuracy: 0.6534 - val_loss: 0.7445 - val_accuracy: 0.4750\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 12s 531ms/step - loss: 0.6061 - accuracy: 0.6364 - val_loss: 0.6981 - val_accuracy: 0.5250\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 12s 553ms/step - loss: 0.5613 - accuracy: 0.7273 - val_loss: 0.6873 - val_accuracy: 0.5500\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 11s 472ms/step - loss: 0.4900 - accuracy: 0.7784 - val_loss: 0.7137 - val_accuracy: 0.4500\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - 11s 481ms/step - loss: 0.4557 - accuracy: 0.8409 - val_loss: 0.7160 - val_accuracy: 0.4500\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 11s 526ms/step - loss: 0.3763 - accuracy: 0.9148 - val_loss: 0.6966 - val_accuracy: 0.5500\n",
      "22/22 [==============================] - 9s 402ms/step - loss: 0.7043 - accuracy: 0.5000\n",
      "6/6 [==============================] - 2s 377ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "10/10 [==============================] - 5s 467ms/step - loss: 0.7055 - accuracy: 0.5000\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 20, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=20, batch_size=16\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 18s 1s/step - loss: 0.7048 - accuracy: 0.5341 - val_loss: 0.6902 - val_accuracy: 0.5312\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.6243 - accuracy: 0.6705 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.5787 - accuracy: 0.7102 - val_loss: 0.7204 - val_accuracy: 0.4375\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 11s 984ms/step - loss: 0.5607 - accuracy: 0.7557 - val_loss: 0.7043 - val_accuracy: 0.5000\n",
      "11/11 [==============================] - 9s 776ms/step - loss: 0.6948 - accuracy: 0.5000\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 0.6944 - accuracy: 0.5000\n",
      "5/5 [==============================] - 5s 916ms/step - loss: 0.6945 - accuracy: 0.5000\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 40, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=40, batch_size=8\n",
      "Epoch 1/40\n",
      "22/22 [==============================] - 17s 601ms/step - loss: 0.7575 - accuracy: 0.4716 - val_loss: 0.6888 - val_accuracy: 0.6250\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - 11s 509ms/step - loss: 0.6540 - accuracy: 0.6193 - val_loss: 0.6941 - val_accuracy: 0.4750\n",
      "Epoch 3/40\n",
      "22/22 [==============================] - 11s 520ms/step - loss: 0.6231 - accuracy: 0.6818 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 4/40\n",
      "22/22 [==============================] - 11s 522ms/step - loss: 0.5334 - accuracy: 0.7614 - val_loss: 0.7047 - val_accuracy: 0.5000\n",
      "22/22 [==============================] - 9s 403ms/step - loss: 0.6931 - accuracy: 0.5398\n",
      "6/6 [==============================] - 2s 287ms/step - loss: 0.6891 - accuracy: 0.5909\n",
      "10/10 [==============================] - 5s 452ms/step - loss: 0.6952 - accuracy: 0.4375\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 40, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=40, batch_size=16\n",
      "Epoch 1/40\n",
      "11/11 [==============================] - 18s 1s/step - loss: 0.7792 - accuracy: 0.4318 - val_loss: 0.7770 - val_accuracy: 0.5312\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6526 - accuracy: 0.5852 - val_loss: 0.7399 - val_accuracy: 0.5625\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.5996 - accuracy: 0.6705 - val_loss: 0.8605 - val_accuracy: 0.4062\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.5541 - accuracy: 0.7386 - val_loss: 0.7870 - val_accuracy: 0.4688\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 11s 984ms/step - loss: 0.4853 - accuracy: 0.8466 - val_loss: 0.7366 - val_accuracy: 0.5312\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 11s 998ms/step - loss: 0.4547 - accuracy: 0.8750 - val_loss: 0.7603 - val_accuracy: 0.4688\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 11s 973ms/step - loss: 0.3613 - accuracy: 0.9205 - val_loss: 0.6951 - val_accuracy: 0.5625\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 10s 944ms/step - loss: 0.3581 - accuracy: 0.8920 - val_loss: 0.7282 - val_accuracy: 0.5312\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 11s 963ms/step - loss: 0.2649 - accuracy: 0.9602 - val_loss: 0.7063 - val_accuracy: 0.5312\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.2444 - accuracy: 0.9432 - val_loss: 0.7415 - val_accuracy: 0.4375\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 0.7334 - accuracy: 0.5000\n",
      "3/3 [==============================] - 2s 468ms/step - loss: 0.7356 - accuracy: 0.5000\n",
      "5/5 [==============================] - 5s 955ms/step - loss: 0.7350 - accuracy: 0.5000\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 60, Batch Size: 8 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=60, batch_size=8\n",
      "Epoch 1/60\n",
      "22/22 [==============================] - 17s 607ms/step - loss: 0.7118 - accuracy: 0.5682 - val_loss: 0.7050 - val_accuracy: 0.5250\n",
      "Epoch 2/60\n",
      "22/22 [==============================] - 12s 521ms/step - loss: 0.6325 - accuracy: 0.6477 - val_loss: 0.6934 - val_accuracy: 0.5500\n",
      "Epoch 3/60\n",
      "22/22 [==============================] - 11s 475ms/step - loss: 0.5865 - accuracy: 0.6932 - val_loss: 0.7026 - val_accuracy: 0.5000\n",
      "Epoch 4/60\n",
      "22/22 [==============================] - 11s 495ms/step - loss: 0.5237 - accuracy: 0.7784 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 5/60\n",
      "22/22 [==============================] - 11s 505ms/step - loss: 0.4593 - accuracy: 0.8068 - val_loss: 0.6888 - val_accuracy: 0.5250\n",
      "Epoch 6/60\n",
      "22/22 [==============================] - 11s 500ms/step - loss: 0.4212 - accuracy: 0.8523 - val_loss: 0.6848 - val_accuracy: 0.5250\n",
      "Epoch 7/60\n",
      "22/22 [==============================] - 12s 515ms/step - loss: 0.3604 - accuracy: 0.8920 - val_loss: 0.6846 - val_accuracy: 0.6000\n",
      "Epoch 8/60\n",
      "22/22 [==============================] - 11s 485ms/step - loss: 0.3290 - accuracy: 0.8920 - val_loss: 0.6816 - val_accuracy: 0.6000\n",
      "Epoch 9/60\n",
      "22/22 [==============================] - 11s 482ms/step - loss: 0.3395 - accuracy: 0.8580 - val_loss: 0.6807 - val_accuracy: 0.5250\n",
      "Epoch 10/60\n",
      "22/22 [==============================] - 11s 501ms/step - loss: 0.2472 - accuracy: 0.9148 - val_loss: 0.7071 - val_accuracy: 0.5000\n",
      "Epoch 11/60\n",
      "22/22 [==============================] - 11s 496ms/step - loss: 0.2421 - accuracy: 0.9091 - val_loss: 0.6639 - val_accuracy: 0.5750\n",
      "Epoch 12/60\n",
      "22/22 [==============================] - 11s 480ms/step - loss: 0.2311 - accuracy: 0.9375 - val_loss: 0.7271 - val_accuracy: 0.5500\n",
      "Epoch 13/60\n",
      "22/22 [==============================] - 11s 482ms/step - loss: 0.1751 - accuracy: 0.9545 - val_loss: 0.6832 - val_accuracy: 0.6000\n",
      "Epoch 14/60\n",
      "22/22 [==============================] - 11s 527ms/step - loss: 0.1406 - accuracy: 0.9716 - val_loss: 0.6241 - val_accuracy: 0.7000\n",
      "Epoch 15/60\n",
      "22/22 [==============================] - 11s 489ms/step - loss: 0.1362 - accuracy: 0.9659 - val_loss: 0.9987 - val_accuracy: 0.5750\n",
      "Epoch 16/60\n",
      "22/22 [==============================] - 10s 474ms/step - loss: 0.1479 - accuracy: 0.9545 - val_loss: 0.9795 - val_accuracy: 0.5500\n",
      "Epoch 17/60\n",
      "22/22 [==============================] - 12s 520ms/step - loss: 0.1269 - accuracy: 0.9659 - val_loss: 0.7592 - val_accuracy: 0.6250\n",
      "22/22 [==============================] - 9s 404ms/step - loss: 0.4320 - accuracy: 0.7614\n",
      "6/6 [==============================] - 2s 324ms/step - loss: 0.6511 - accuracy: 0.6591\n",
      "10/10 [==============================] - 5s 489ms/step - loss: 0.6961 - accuracy: 0.6000\n",
      "\n",
      "===== Fine-tuning ResNet50 - Epochs: 60, Batch Size: 16 =====\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Fine-tuning model: Unfrozen 35 layers out of 175 total layers in the base model.\n",
      "Training fine-tuned ResNet50 with epochs=60, batch_size=16\n",
      "Epoch 1/60\n",
      "11/11 [==============================] - 18s 1s/step - loss: 0.7722 - accuracy: 0.4318 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 2/60\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.6235 - accuracy: 0.6818 - val_loss: 0.6983 - val_accuracy: 0.5000\n",
      "Epoch 3/60\n",
      "11/11 [==============================] - 11s 1s/step - loss: 0.5799 - accuracy: 0.7273 - val_loss: 0.7015 - val_accuracy: 0.5000\n",
      "Epoch 4/60\n",
      "11/11 [==============================] - 11s 995ms/step - loss: 0.5050 - accuracy: 0.8125 - val_loss: 0.7128 - val_accuracy: 0.4688\n",
      "Epoch 5/60\n",
      "11/11 [==============================] - 11s 973ms/step - loss: 0.4765 - accuracy: 0.8523 - val_loss: 0.7223 - val_accuracy: 0.4375\n",
      "11/11 [==============================] - 8s 724ms/step - loss: 0.6980 - accuracy: 0.5000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.6985 - accuracy: 0.5000\n",
      "5/5 [==============================] - 5s 976ms/step - loss: 0.7008 - accuracy: 0.5000\n",
      "\n",
      "All processes completed successfully!\n",
      "Results saved to: C:/Users/user/Desktop/MLWORK/ResNet50\n"
     ]
    }
   ],
   "source": [
    "# 主函數\n",
    "def main():\n",
    "    # 創建CSV結果文件\n",
    "    csv_files = create_result_csv_files()\n",
    "    \n",
    "    model_name = \"ResNet50\"\n",
    "    all_results = {}  # 儲存所有結果以供後續比較\n",
    "    \n",
    "    # 第1階段：訓練和評估基礎模型\n",
    "    print(\"======== Stage 1: Training and Evaluating Base Models ========\")\n",
    "    \n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            print(f\"\\n===== Training Base {model_name} - Epochs: {epochs}, Batch Size: {batch_size} =====\")\n",
    "            \n",
    "            # 創建資料生成器\n",
    "            train_gen, val_gen, test_gen = create_data_generators(batch_size)\n",
    "            \n",
    "            # 創建基礎模型\n",
    "            base_model = create_resnet_model()\n",
    "            \n",
    "            # 訓練和評估基礎模型\n",
    "            base_results = train_and_evaluate_model(\n",
    "                base_model, train_gen, val_gen, test_gen,\n",
    "                model_name, epochs, batch_size, is_fine_tuned=False\n",
    "            )\n",
    "            \n",
    "            # 保存結果到CSV\n",
    "            save_results_to_csv(\n",
    "                base_results, csv_files['base'], \n",
    "                model_name, epochs, is_fine_tuned=False\n",
    "            )\n",
    "            \n",
    "            # 保存模型結果以供後續比較\n",
    "            result_key = f\"{model_name}_e{epochs}_b{batch_size}\"\n",
    "            all_results[result_key] = {'base': base_results}\n",
    "            \n",
    "            # 清理內存\n",
    "            tf.keras.backend.clear_session()\n",
    "    \n",
    "    # 第2階段：微調模型\n",
    "    print(\"\\n======== Stage 2: Fine-tuning Models ========\")\n",
    "    \n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            print(f\"\\n===== Fine-tuning {model_name} - Epochs: {epochs}, Batch Size: {batch_size} =====\")\n",
    "            \n",
    "            # 創建資料生成器 (重新創建是為了確保數據的一致性)\n",
    "            train_gen, val_gen, test_gen = create_data_generators(batch_size)\n",
    "            \n",
    "            # 創建模型\n",
    "            tuned_model = create_resnet_model()\n",
    "            \n",
    "            # 微調模型\n",
    "            tuned_model = fine_tune_model(tuned_model)\n",
    "            \n",
    "            # 訓練和評估微調後的模型\n",
    "            tuned_results = train_and_evaluate_model(\n",
    "                tuned_model, train_gen, val_gen, test_gen,\n",
    "                model_name, epochs, batch_size, is_fine_tuned=True\n",
    "            )\n",
    "            \n",
    "            # 保存結果到CSV\n",
    "            save_results_to_csv(\n",
    "                tuned_results, csv_files['tuned'], \n",
    "                model_name, epochs, is_fine_tuned=True\n",
    "            )\n",
    "            \n",
    "            # 添加到結果字典\n",
    "            result_key = f\"{model_name}_e{epochs}_b{batch_size}\"\n",
    "            if result_key in all_results:\n",
    "                all_results[result_key]['tuned'] = tuned_results\n",
    "                \n",
    "                # 保存比較結果\n",
    "                base_results = all_results[result_key]['base']\n",
    "                save_comparison_to_csv(\n",
    "                    base_results, tuned_results, csv_files['comparison'],\n",
    "                    model_name, epochs\n",
    "                )\n",
    "            \n",
    "            # 清理內存\n",
    "            tf.keras.backend.clear_session()\n",
    "    \n",
    "    print(\"\\nAll processes completed successfully!\")\n",
    "    print(f\"Results saved to: {results_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d55f5-9d49-49a0-a13e-c5a3799d27cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
